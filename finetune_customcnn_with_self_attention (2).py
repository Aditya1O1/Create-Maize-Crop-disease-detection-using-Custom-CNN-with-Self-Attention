# -*- coding: utf-8 -*-
"""FineTune CustomCNN with Self ATTENTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gEWGAp7mOzGPJJhGHXe4vpYY3Mjy3q2t
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')
data_dir = '/content/drive/MyDrive/archive/data'

# Prepare file paths and labels
filepaths = []
labels = []

folds = os.listdir(data_dir)
for fold in folds:
    foldpath = os.path.join(data_dir, fold)
    filelist = os.listdir(foldpath)
    for file in filelist:
        fpath = os.path.join(foldpath, file)
        filepaths.append(fpath)
        labels.append(fold)

# Encode labels
le = LabelEncoder()
labels_encoded = le.fit_transform(labels)

# Split data
train_files, test_files, train_labels, test_labels = train_test_split(
    filepaths, labels_encoded, test_size=0.2, stratify=labels_encoded, random_state=42)
train_files, val_files, train_labels, val_labels = train_test_split(
    train_files, train_labels, test_size=0.2, stratify=train_labels, random_state=42)



# Constants
IMG_SIZE = 128
BATCH_SIZE = 32
EPOCHS = 15

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

import pandas as pd

train_gen = train_datagen.flow_from_dataframe(
    dataframe=pd.DataFrame({'filename': train_files, 'class': train_labels}),
    x_col='filename', y_col='class',
    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE,
    class_mode='raw', shuffle=True
)

val_gen = val_datagen.flow_from_dataframe(
    dataframe=pd.DataFrame({'filename': val_files, 'class': val_labels}),
    x_col='filename', y_col='class',
    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE,
    class_mode='raw', shuffle=False
)

test_gen = test_datagen.flow_from_dataframe(
    dataframe=pd.DataFrame({'filename': test_files, 'class': test_labels}),
    x_col='filename', y_col='class',
    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE,
    class_mode='raw', shuffle=False
)

from tensorflow.keras.layers import Layer

class SelfAttention(Layer):
    def __init__(self, filters, **kwargs):
        super(SelfAttention, self).__init__(**kwargs)
        self.filters = filters

    def build(self, input_shape):
        self.query_conv = layers.Conv2D(self.filters // 8, kernel_size=1, padding='same')
        self.key_conv = layers.Conv2D(self.filters // 8, kernel_size=1, padding='same')
        self.value_conv = layers.Conv2D(self.filters, kernel_size=1, padding='same')
        self.output_conv = layers.Conv2D(self.filters, kernel_size=1, padding='same')
        super(SelfAttention, self).build(input_shape)

    def call(self, inputs):
        q = self.query_conv(inputs)
        k = self.key_conv(inputs)
        v = self.value_conv(inputs)

        # Compute attention map
        attention_map = tf.nn.softmax(tf.matmul(tf.reshape(q, (-1, q.shape[1] * q.shape[2], q.shape[3])),
                                                tf.reshape(k, (-1, k.shape[1] * k.shape[2], k.shape[3])), transpose_b=True))

        # Apply attention map to values
        out = tf.matmul(attention_map, tf.reshape(v, (-1, v.shape[1] * v.shape[2], v.shape[3])))
        out = tf.reshape(out, (-1, inputs.shape[1], inputs.shape[2], self.filters))
        out = self.output_conv(out)
        return layers.Add()([inputs, out])

# Modify model function to use the custom Self-Attention layer
def create_model(input_shape, num_classes):
    inputs = layers.Input(shape=input_shape)

    # Initial Convolutional Layers
    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.BatchNormalization()(x)

    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.BatchNormalization()(x)

    # Self-Attention Block
    x = SelfAttention(64)(x)

    # Further Convolutional Layers
    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.BatchNormalization()(x)

    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.BatchNormalization()(x)

    # Fully Connected Layers
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)

    model = models.Model(inputs, outputs)
    return model

# Compile Model
input_shape = (IMG_SIZE, IMG_SIZE, 3)
num_classes = len(le.classes_)
model = create_model(input_shape, num_classes)

model.compile(optimizer=optimizers.Adam(learning_rate=0.001),
              loss='sparse_categorical_crossentropy', metrics=['accuracy'])

def process_image(file_path, label):
    img = tf.io.read_file(file_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])
    img = img / 255.0  # Normalize to [0,1]
    return img, label

# Create TensorFlow datasets
train_ds = tf.data.Dataset.from_tensor_slices((train_files, train_labels))
val_ds = tf.data.Dataset.from_tensor_slices((val_files, val_labels))
test_ds = tf.data.Dataset.from_tensor_slices((test_files, test_labels))

train_ds = (train_ds.map(process_image)
                    .shuffle(buffer_size=1000)
                    .batch(BATCH_SIZE)
                    .prefetch(tf.data.AUTOTUNE))

val_ds = (val_ds.map(process_image)
                  .batch(BATCH_SIZE)
                  .prefetch(tf.data.AUTOTUNE))

test_ds = (test_ds.map(process_image)
                   .batch(BATCH_SIZE)
                   .prefetch(tf.data.AUTOTUNE))

# Model Training
EPOCHS = 15
history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)

# Model Evaluation
test_loss, test_accuracy = model.evaluate(test_ds)
print(f"Test Accuracy: {test_accuracy:.2f}")





# Confusion Matrix and Classification Report
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Predict labels for the test set
y_pred_probs = model.predict(test_ds)
y_pred = np.argmax(y_pred_probs, axis=1)

# Confusion Matrix
cm = confusion_matrix(test_labels, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# Classification Report
print("Classification Report:\n", classification_report(test_labels, y_pred, target_names=le.classes_))

"""Making Predictions and Displaying Resultsg"""

import matplotlib.pyplot as plt
import numpy as np

# Generate predictions for the test set
y_pred_probs = model.predict(test_ds)  # Probabilities for each class
y_pred = np.argmax(y_pred_probs, axis=1)  # Predicted class labels

# Sample a few test images for display with their actual and predicted labels
test_images = []
test_labels_disp = []
predicted_labels_disp = []

# Loop through a small sample of test images
for img, label in test_ds.take(5):  # Display 5 batches of test images
    test_images.extend(img.numpy())  # Add images to list
    test_labels_disp.extend(label.numpy())  # Add true labels to list
    predicted_labels_disp.extend(y_pred[:len(label)])  # Add predicted labels to list
    y_pred = y_pred[len(label):]  # Update remaining predictions

# Define a function to display images with actual and predicted labels
def plot_predictions(images, true_labels, predicted_labels, class_names):
    plt.figure(figsize=(12, 10))
    for i in range(len(images)):
        plt.subplot(3, 3, i + 1)  # Display in a 3x3 grid
        plt.imshow(images[i])
        true_class = class_names[true_labels[i]]
        pred_class = class_names[predicted_labels[i]]
        plt.title(f"True: {true_class}\nPred: {pred_class}", color=("green" if true_class == pred_class else "red"))
        plt.axis("off")
    plt.tight_layout()
    plt.show()

# Plotting sample predictions
plot_predictions(test_images[:9], test_labels_disp[:9], predicted_labels_disp[:9], le.classes_)





"""Plotting the Modelâ€™s Training History"""

# Plot accuracy and loss over epochs
plt.figure(figsize=(14, 6))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()